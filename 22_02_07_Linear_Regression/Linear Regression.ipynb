{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58b34137",
   "metadata": {},
   "outputs": [],
   "source": [
    ">>Adjusted-R^2 \n",
    "\n",
    ">>Assumptions\n",
    "\n",
    ">>VIF\n",
    ">>OLS\n",
    ">>SGD\n",
    "\n",
    ">>Evaluation metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02b09e35",
   "metadata": {},
   "outputs": [],
   "source": [
    ">>Adjusted-R^2 :\n",
    "    - Modified version of R^2\n",
    "    - It will increase only when we add good predictors\n",
    "    - A-R^2 will always less than or eqaul to R^2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffcbcdb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "A-R^2 = 1- (((1-R^2)*(n-1))/(n-k-1))\n",
    "        n = sample size\n",
    "        k = no. of ind var\n",
    "        r^2 = Coeff. of deter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cbd617a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9238461538461539"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2= 0.93\n",
    "A_r2 = 1- (((1-r2)*(100-1))/(100-8-1))\n",
    "A_r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eb09a327",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4560439560439561"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2= 0.5\n",
    "A_r2 = 1- (((1-r2)*(100-1))/(100-8-1))\n",
    "A_r2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fbb1361",
   "metadata": {},
   "source": [
    "## Linear Regression Assumptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22a976c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "1) Linearity >> Model assumes that their is linear relationship between dependent and independent\n",
    "var.\n",
    "\n",
    "2) Independance >> Model assumes ind var are independent of each other\n",
    "\n",
    "3) Normality of error distribution >>  The error should be normally distributed across the model,\n",
    "\n",
    "4) Homoscedasticity (Same variance/error) >> The spread of errors across the model for range of x \n",
    "                                                should remain constant or same\n",
    "    \n",
    "5) No Multicolinearity >> High correlation between ind var, so it is difficult to find relation between predictor\n",
    "                            and target var\n",
    "    \n",
    "6) Mean of residuals is zero >> Because we try to get BFL exactly in the middle of residuals,residuals gets seggregated\n",
    "        in positive and negative, and they might cancel out each other, and comes close to zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "073a69a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "v1 >> 0.85\n",
    "v2 >> 0.83"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7f4571c",
   "metadata": {},
   "outputs": [],
   "source": [
    "wt (v1)\n",
    "hp (v2)\n",
    "speed (T)\n",
    "\n",
    "v1 > T = 0.83\n",
    "v2 > T = 0.85\n",
    "v1 > v2 = 0.86"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f71a294",
   "metadata": {},
   "outputs": [],
   "source": [
    ">> Varinace inflation factor(VIF) >> It detects Multicolinearity\n",
    "    - VIF ranges from 1 onwards\n",
    "    - VIF = 1 >> Not correlated\n",
    "    -     1 to 5 >> moderate correlation\n",
    "    -     more than 5 >> highly correlated\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4a5245f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ordinary least squares (OLS) >> It is statistical method to estimate the relation by minimizing the Sum of squares in diff of\n",
    "                                act and pred values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df2b0fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "Stochastic Gradient Descent (SGD): \n",
    "    - we have 100 observations and 10 features\n",
    "    - when we compute dreivative 100 *10 = 1000\n",
    "    - Its common to take 1000 iterations, 1000 *1000 = 1000000\n",
    "    - Gradient descent is slow on huge data\n",
    "    - Stochastic = random\n",
    "    - It picks randomly 1 observation per instance, >> mini-batch GD\n",
    "    - SGD works faster with huge datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfbae930",
   "metadata": {},
   "source": [
    "## Evaluation Metrics for Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8c706ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "cost function/loss function : It is a parameter we try to optimize/minimise in gradient descent\n",
    "    \n",
    "    So all metrics are cost functions itself.\n",
    " \n",
    "1) Mean Absolute Error (MAE) : It is absolute diff between act and pred  (MAPE : Mean Absolute Percentage Error)\n",
    "    - Optimal pred values will be around median of target values.\n",
    "    - median is robust to outliers\n",
    "    - MAE is robust to outliers.\n",
    "    \n",
    "    MAE = sum ((|act - pre|)/n)\n",
    "    \n",
    "2) Mean Squared Error (MSE):\n",
    "    \n",
    "    MSE = sum ((act - pre)^2/n)\n",
    "    \n",
    "    - most commmonly used cost function\n",
    "    - It tells us performance of our model\n",
    "    - beacuse we penelize the errors. \n",
    "    - It is sensitive to outliers\n",
    "    - Optimal pred values will be around mean of target values.\n",
    "    \n",
    "3) Root Mean Squared Error(RMSE):\n",
    "     \n",
    "        RMSE = sqrt(sum ((act - pre)^2/n))\n",
    "    - preffered to use in deep learning\n",
    "    - not that robust comapare to MAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7a3b689",
   "metadata": {},
   "outputs": [],
   "source": [
    "Advantages: \n",
    "    1) Simple to implement\n",
    "    2) Simple to interpret\n",
    "    3) performs better when there is] linearity\n",
    "    4) scaling does not affect the model\n",
    "    5) dimensional reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e979f0f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "Disadvanatage:\n",
    "    1) Assumption of linear regression\n",
    "    2) Outlier affect the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f89c51bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e06d4830",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55b1e823",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "467ed2bb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
